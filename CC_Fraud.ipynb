{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\mbadi\\\\Desktop\\\\Kaggle_Projects\\\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations of this data set are individual credit card transactions. The target variable is whether or not the transaction was fraudulent (True for fraud, False for legitimate). Variables V1-V28 are in fact principal components. The goal is to conduct classification- whether we can predict that a given credit card transaction is fraud or not. \n",
    "\n",
    "First, the data is highly imbalanced in favor of non-fraudulent transactions. One remedy is to take a random subset of the majority class that is the same size as the minority class and analyze that unioned dataset. To this end, we'll employ Scikit Learn's Stratified Shuffle Split to establish the train/test datasets so that the True/False ratio of the target variable is the same for both. Putting the test set aside, we'll then balance out the train dataset as specified above. Once the data has been preprocessed, we'll have the green light to deploy an ensemble of classifiers to maximize recall. We favor recall over precision because we'd rather capture every truly fraudulent case, even if we misidentify truly non-fraudulent cases in the process. \n",
    "\n",
    "Regarding the variables, we'll drop \"Time\" and normalize \"Amount\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"Time\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Amount_Norm\"] = StandardScaler().fit_transform(data[\"Amount\"].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"Amount\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Amount_Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  Amount_Norm  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0     0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0    -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0     1.160686  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0     0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0    -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to split the data into train/test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in split.split(data, data[\"Class\"]):\n",
    "    data_train = data.loc[train_index]\n",
    "    data_test = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the test/train sets have the same True/False ratio in Class, let's take value counts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998271\n",
       "1    0.001729\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"Class\"].value_counts()/len(data_train[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.99828\n",
       "1    0.00172\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[\"Class\"].value_counts()/len(data_test[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and indeed they do (close enough).\n",
    "\n",
    "Now we'll need to balance the train set. Balancing is necessary so that the ML algorithms don't attribute to underlying cause what can be attributed to sampling. \n",
    "\n",
    "We won't balance the test set, since this imbalance is characteristic of the reality of credit card fraud. The following code pertains to the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_count = len(data_train[data_train.Class==True])\n",
    "fraud_indices = np.array(data_train[data_train.Class==True].index)\n",
    "normal_indices = np.array(data_train[data_train.Class==False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_normal_indices = np.random.choice(normal_indices, fraud_count, replace=False)\n",
    "random_normal_indices = np.array(random_normal_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_sample_indices = np.concatenate([fraud_indices, random_normal_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_sample_data = data_train.loc[balanced_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_sample_data[\"Class\"].value_counts()/len(balanced_sample_data[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our train data set is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 788 entries, 42887 to 106071\n",
      "Data columns (total 30 columns):\n",
      "V1             788 non-null float64\n",
      "V2             788 non-null float64\n",
      "V3             788 non-null float64\n",
      "V4             788 non-null float64\n",
      "V5             788 non-null float64\n",
      "V6             788 non-null float64\n",
      "V7             788 non-null float64\n",
      "V8             788 non-null float64\n",
      "V9             788 non-null float64\n",
      "V10            788 non-null float64\n",
      "V11            788 non-null float64\n",
      "V12            788 non-null float64\n",
      "V13            788 non-null float64\n",
      "V14            788 non-null float64\n",
      "V15            788 non-null float64\n",
      "V16            788 non-null float64\n",
      "V17            788 non-null float64\n",
      "V18            788 non-null float64\n",
      "V19            788 non-null float64\n",
      "V20            788 non-null float64\n",
      "V21            788 non-null float64\n",
      "V22            788 non-null float64\n",
      "V23            788 non-null float64\n",
      "V24            788 non-null float64\n",
      "V25            788 non-null float64\n",
      "V26            788 non-null float64\n",
      "V27            788 non-null float64\n",
      "V28            788 non-null float64\n",
      "Class          788 non-null int64\n",
      "Amount_Norm    788 non-null float64\n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 190.8 KB\n"
     ]
    }
   ],
   "source": [
    "balanced_sample_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = balanced_sample_data.drop(\"Class\", axis=1, inplace=False).copy()\n",
    "y_train = pd.DataFrame(balanced_sample_data[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the data is also normalized and there are no missing values. We can proceed to train ML algorithms.\n",
    "\n",
    "The only problem is that we've drastically reduced the number of observations, which means we risk falling prey to the \"curse of dimensionality\". In short, we need to decide on a handful of variables that most influence our target variable.\n",
    "\n",
    "Let's see how the variables correlate with \"Class\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_train.corr() #computes correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d88c7c99e8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that V12, V14, and V17 have relatively high negative correlation with the target variable. Let's consider training a model using these three predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first implement logistic regression in conjunction with a cross-validator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_cols = [\"V12\",\"V14\",\"V17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lr, X_train[chosen_cols], y_train, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9301819212533498, 0.008460924671141542)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regressor yields decent accuracy. Let's test another ML algorithm to be sure that the logistic regressor is not overfitting our data. Next we'll try a support vector machine classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC() #we initialize a naive classifier, to then fine-tune as we please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = cross_val_score(svc, X_train[chosen_cols], y_train, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9403602350030922, 0.007429857488273562)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scores1.mean(), scores1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM classifier slightly outperforms the logistic regressor. It's likely that we can further improve this performance by fine-tuning the SVM's hyperparameters. \n",
    "\n",
    "To this end, we'll use ScikitLearn's Grid Search CV, which iterates across a given hyperparameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear','rbf'), 'C':[0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train[chosen_cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimum_score = cross_val_score(svc, X_train[chosen_cols], y_train, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9403602350030922, 0.007429857488273562)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(optimum_score.mean(), optimum_score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine-tuning procedure didn't much improve performance. Let's test this svm on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test[chosen_cols]\n",
    "y_test = data_test[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681717636318949"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, svc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like an outstanding score, and it is. The problem is that since the test set is drastically imbalanced, this score may not reflect the true accuracy of our model, in that the 3% of the data that is misclassified could contain more fraudulent cases than we're comfortable with. Let's balance the test set and try this again.\n",
    "\n",
    "We'll repeat the resampling procedure as in the Data Preprocessing section, but this time with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "frd_count = len(data_test[data_test[\"Class\"]==True])\n",
    "frd_indices = np.array(data_test[data_test.Class==True].index)\n",
    "norm_indices = np.array(data_test[data_test.Class==False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_norm_indices = np.random.choice(norm_indices, frd_count, replace=False)\n",
    "rand_norm_indices = np.array(rand_norm_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_indices = np.concatenate([frd_indices, rand_norm_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_test = data_test.loc[bal_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_test[\"Class\"].value_counts()/len(bal_test[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a balanced test set. All that's left is to use it to check our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bal = bal_test[chosen_cols]\n",
    "y_test_bal = bal_test[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387755102040817"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_bal, svc.predict(X_test_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though balancing the test set caused a noticeable drop in accuracy, our model still performs at almost 94%.\n",
    "\n",
    "For future reference, the predictive ability of the model can be improved if it's used as part of an ensemble. Such an ensemble in this case might consist of the SVM, the logistic regressor, and a decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you to Kaggle and to the Scikit Learn team.\n",
    "\n",
    "Link to kaggle dataset:\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
